{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quyongkeomut/Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow---my-practice/blob/main/Chapter_14_Computer_Vision_using_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lZxovFDONJw"
      },
      "source": [
        "### Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmyKTLFQB5pK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = keras.layers.Conv2D(25, 3, padding=\"same\", )"
      ],
      "metadata": {
        "id": "I1hzBG6niNul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRexC_LEKc5u"
      },
      "source": [
        "##Flower Dataset  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "96ee3dba90d543a69b868e4c31642c5b",
            "3dd0c096ebdb4d94a5776ae4d5a2441d",
            "0c410e2b0ee344cc95770b06a8efc8b2",
            "5aad7bac3b96432493c47381e72af3b2",
            "e5ae900f485847a4ae917f5889305b1e",
            "305f6a099992467da877923174cee107",
            "a1577d1009ff4d82a8a2438df5fcf89e",
            "09a88738561943b9a0150286a6c2a27f",
            "2676a56848c0409a89127512d68fce8e",
            "0ecedb6245de4371bb774acb8ae0d939",
            "68740fa190bc43e785282c7c9e79c3b6"
          ]
        },
        "id": "vi-TMunVngsC",
        "outputId": "eaec8195-06c2-47c7-d1f3-311bb5dadd1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96ee3dba90d543a69b868e4c31642c5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "flowers_ds, flowers_ds_info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzGC7mw9oVMR",
        "outputId": "92d8812b-9958-47e5-e395-04c5935c6dd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "flowers_ds_size = flowers_ds_info.splits[\"train\"].num_examples\n",
        "flowers_ds_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdh8KBdWofZT",
        "outputId": "ad3c4069-17f4-43af-c452-ff448d063558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "flowers_class_names = flowers_ds_info.features[\"label\"].names\n",
        "flowers_class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufGIBQ1Motkc",
        "outputId": "5d206e69-d6c3-4113-f639-c6293852ec86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "num_classes = flowers_ds_info.features[\"label\"].num_classes\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGZwTJcmtDdf"
      },
      "source": [
        "However, this dataset just have one train subset \"train\" and do not have any other subset, such as \"validation\" or \"test\". Because of that, we split this \"train\" set to multiple subsets: first 10% for testing, next 15% for validation and the 75% remainer for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8i75xbKv-H0"
      },
      "outputs": [],
      "source": [
        "flowers_test, flowers_valid, flowers_train = tfds.load(\"tf_flowers\", split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"], as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jva_fbFeAKuV"
      },
      "source": [
        "We must also preprocess the whole subsets. This Xception requires 224 $\\times$ 224 images, so we write the transform procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-kbN34BAJhR"
      },
      "outputs": [],
      "source": [
        "def flowers_preprocess(image, label):\n",
        "    resized_image = tf.image.resize(image, [224, 224])\n",
        "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "    return final_image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V41X1KKMqqG"
      },
      "source": [
        "Preprocess the three subsets, shuffle them, and then pack as prefetched batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljC54hP0DKKv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "flowers_train = flowers_train.shuffle(1000, reshuffle_each_iteration=True)\n",
        "\n",
        "flowers_train = flowers_train.map(flowers_preprocess).batch(batch_size).prefetch(1)\n",
        "flowers_valid = flowers_valid.map(flowers_preprocess).batch(batch_size).prefetch(1)\n",
        "flowers_test = flowers_test.map(flowers_preprocess).batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heBvcdeoiNPY"
      },
      "source": [
        "## **AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-xZvg3AigEj"
      },
      "outputs": [],
      "source": [
        "class AlexNet(keras.Model):\n",
        "    def __init__(self, output_dim=10, input_dim=[320, 320, 3], **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.layer = [\n",
        "            keras.layers.InputLayer(input_shape=self.input_dim, name=\"input\"),\n",
        "            keras.layers.Conv2D(filters=96,\n",
        "                                kernel_size=11,\n",
        "                                strides=4,\n",
        "                                padding=\"valid\",\n",
        "                                activation=\"relu\",\n",
        "                                name=\"conv_layer_1\"),\n",
        "            keras.layers.Lambda(lambda X: tf.nn.local_response_normalization(X, depth_radius=2,\n",
        "                                                                             alpha=2e-5, beta=0.75, bias=1),\n",
        "                                name=\"local_response_normalization_layer1\"),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"valid\",\n",
        "                                   name=\"maxpool_layer_2\"),\n",
        "            keras.layers.Conv2D(filters=256,\n",
        "                                kernel_size=5,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\",\n",
        "                                name=\"conv_layer_3\"),\n",
        "            keras.layers.Lambda(lambda X: tf.nn.local_response_normalization(X, depth_radius=2,\n",
        "                                                                             alpha=2e-5, beta=0.75, bias=1),\n",
        "                                name=\"local_response_normalization_layer2\"),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"valid\",\n",
        "                                   name=\"maxpool_layer_4\"),\n",
        "            keras.layers.Conv2D(filters=384,\n",
        "                                kernel_size=3,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\",\n",
        "                                name=\"conv_layer_5\"),\n",
        "            keras.layers.Conv2D(filters=384,\n",
        "                                kernel_size=3,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\",\n",
        "                                name=\"conv_layer_6\"),\n",
        "            keras.layers.Conv2D(filters=256,\n",
        "                                kernel_size=3,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\",\n",
        "                                name=\"conv_layer_7\"),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"valid\",\n",
        "                                   name=\"maxpool_layer_8\"),\n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dense(4096, activation=\"relu\", name=\"hidden9\"),\n",
        "            keras.layers.Dropout(0.5),\n",
        "            keras.layers.Dense(4096, activation=\"relu\", name=\"hidden10\"),\n",
        "            keras.layers.Dropout(0.5),\n",
        "            keras.layers.Dense(self.output_dim, activation=\"relu\", name=\"output\")\n",
        "        ]\n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "      super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "        Z = X\n",
        "        for layer in self.layer:\n",
        "            Z = layer(Z)\n",
        "        return Z\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config,\n",
        "                \"output_dim\": self.output_dim,\n",
        "                \"input_dim\": self.input_dim}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_NiPnfwjqQU"
      },
      "outputs": [],
      "source": [
        "alexnet_model = AlexNet(output_dim=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIGD7Yy0kv4y"
      },
      "outputs": [],
      "source": [
        "alexnet_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                      optimizer=\"adam\",\n",
        "                      metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "iSUzuKPik_fk",
        "outputId": "28833c0b-5e4c-489d-db8b-0383181784cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n",
            "86/86 [==============================] - 623s 7s/step - loss: 1.6731 - accuracy: 0.2398 - val_loss: 1.6094 - val_accuracy: 0.2377\n",
            "Epoch 2/23\n",
            "86/86 [==============================] - 557s 6s/step - loss: 1.6094 - accuracy: 0.2402 - val_loss: 1.6094 - val_accuracy: 0.2377\n",
            "Epoch 3/23\n",
            "86/86 [==============================] - 567s 7s/step - loss: 1.6094 - accuracy: 0.2402 - val_loss: 1.6094 - val_accuracy: 0.2377\n",
            "Epoch 4/23\n",
            "86/86 [==============================] - 571s 7s/step - loss: 1.6094 - accuracy: 0.2402 - val_loss: 1.6094 - val_accuracy: 0.2377\n",
            "Epoch 5/23\n",
            " 7/86 [=>............................] - ETA: 7:58 - loss: 1.6094 - accuracy: 0.2500"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cff0aa7e054b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malexnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflowers_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflowers_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "alexnet_model.fit(flowers_train, validation_data=flowers_valid, epochs=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkKI7j2hCL2d"
      },
      "source": [
        "## **GoogLeNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fw0AcFR92Kw"
      },
      "source": [
        "\n",
        "\n",
        "### Module Inception\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1HsOiaScv1hsuP9k8BCDjb-JCQ-ZZQjiY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQBNucvjCVA3"
      },
      "outputs": [],
      "source": [
        "class InceptionBlock(keras.layers.Layer):\n",
        "    def __init__(self, num_channels_each_conv, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.num_channels_each_conv = num_channels_each_conv\n",
        "        self.first_layers = [\n",
        "            keras.layers.Conv2D(kernel_size=1,\n",
        "                                filters=self.num_channels_each_conv[4],\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.Conv2D(kernel_size=1,\n",
        "                                filters=self.num_channels_each_conv[5],\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=1,\n",
        "                                   padding=\"same\")\n",
        "        ]\n",
        "        self.second_layers = [\n",
        "            keras.layers.Conv2D(kernel_size=1,\n",
        "                                filters=self.num_channels_each_conv[0],\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.Conv2D(kernel_size=3,\n",
        "                                filters=self.num_channels_each_conv[1],\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.Conv2D(kernel_size=5,\n",
        "                                filters=self.num_channels_each_conv[2],\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.Conv2D(kernel_size=1,\n",
        "                                filters=self.num_channels_each_conv[3],\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "        ]\n",
        "        self.out = keras.layers.Concatenate()\n",
        "\n",
        "    def call(self, X):\n",
        "       first_out_first_layers = self.first_layers[0](X)\n",
        "       second_out_first_layers = self.first_layers[1](X)\n",
        "       third_out_first_layers = self.first_layers[2](X)\n",
        "\n",
        "       first_out_second_layers = self.second_layers[0](X)\n",
        "       second_out_second_layers = self.second_layers[1](first_out_first_layers)\n",
        "       third_out_second_layers = self.second_layers[2](second_out_first_layers)\n",
        "       fourth_out_second_layers = self.second_layers[3](third_out_first_layers)\n",
        "       return self.out([first_out_second_layers, second_out_second_layers, third_out_second_layers, fourth_out_second_layers])\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"num_channels_each_conv\": self.num_channels_each_conv}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfoOaBRHBz2O"
      },
      "source": [
        "### GoogeLenet architecture\n",
        "![](https://drive.google.com/uc?export=view&id=10KWIclw7gzoOWLOR2VGqQoTZk8t8e94u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unNXK8tnCV4Y"
      },
      "outputs": [],
      "source": [
        "class GoogLeNet(keras.Model):\n",
        "    def __init__(self, input_dim=[224, 224, 3], output_dim=10, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.layer = [\n",
        "            keras.layers.InputLayer(input_shape=input_dim),\n",
        "            keras.layers.Conv2D(filters=64,\n",
        "                                kernel_size=7,\n",
        "                                strides=2,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"same\"),\n",
        "            keras.layers.Lambda(lambda X: tf.nn.local_response_normalization(X, depth_radius=2,\n",
        "                                                                             alpha=2e-5, beta=0.75, bias=1)),\n",
        "            keras.layers.Conv2D(filters=64,\n",
        "                                kernel_size=1,\n",
        "                                strides=1,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.Conv2D(filters=192,\n",
        "                                kernel_size=3,\n",
        "                                strides=1,\n",
        "                                padding=\"same\",\n",
        "                                activation=\"relu\"),\n",
        "            keras.layers.Lambda(lambda X: tf.nn.local_response_normalization(X, depth_radius=2,\n",
        "                                                                             alpha=2e-5, beta=0.75, bias=1)),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"same\"),\n",
        "            InceptionBlock((64, 128, 32, 32, 96, 16)),\n",
        "            InceptionBlock((128, 192, 96, 64, 128, 32)),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"same\"),\n",
        "            InceptionBlock((192, 208, 48, 64, 96, 16)),\n",
        "            InceptionBlock((160, 224, 64, 64, 112, 24)),\n",
        "            InceptionBlock((128, 256, 64, 64, 128, 24)),\n",
        "            InceptionBlock((112, 288, 64, 64, 144, 32)),\n",
        "            InceptionBlock((256, 320, 128, 128, 160, 32)),\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"same\"),\n",
        "            InceptionBlock((256, 320, 128, 128, 160, 32)),\n",
        "            InceptionBlock((384, 384, 128, 128, 192, 48)),\n",
        "            keras.layers.GlobalAvgPool2D(),\n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dropout(0.4),\n",
        "            keras.layers.Dense(output_dim, activation=\"softmax\")\n",
        "        ]\n",
        "\n",
        "    def call(self, X):\n",
        "        Z = X\n",
        "        for layer in self.layer:\n",
        "            Z = layer(Z)\n",
        "        return Z\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"input_dim\": self.input_dim,\n",
        "                \"output_dim\": self.output_dim}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wKFkplIKKta"
      },
      "outputs": [],
      "source": [
        "googlenet = GoogLeNet()\n",
        "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.05, momentum=0.9, nesterov=True, decay=0.01)\n",
        "googlenet.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "                  metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjHEQWAMKg2J",
        "outputId": "73e7650e-ee61-4cd3-97b1-4ebe4e5c579b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "86/86 [==============================] - 19s 188ms/step - loss: 1.7045 - accuracy: 0.2115 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 1.3976 - accuracy: 0.3710 - val_loss: 1.2108 - val_accuracy: 0.5082\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 1.1435 - accuracy: 0.5069 - val_loss: 1.0113 - val_accuracy: 0.5862\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 1.0121 - accuracy: 0.5836 - val_loss: 0.9672 - val_accuracy: 0.6116\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 0.9362 - accuracy: 0.6097 - val_loss: 0.9189 - val_accuracy: 0.6388\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 16s 184ms/step - loss: 0.8548 - accuracy: 0.6414 - val_loss: 0.8337 - val_accuracy: 0.6878\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 16s 182ms/step - loss: 0.8079 - accuracy: 0.6693 - val_loss: 0.8452 - val_accuracy: 0.6570\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 16s 180ms/step - loss: 0.7823 - accuracy: 0.6777 - val_loss: 0.7879 - val_accuracy: 0.6933\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 16s 182ms/step - loss: 0.7513 - accuracy: 0.6969 - val_loss: 0.7812 - val_accuracy: 0.7096\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 16s 183ms/step - loss: 0.7248 - accuracy: 0.7057 - val_loss: 0.7448 - val_accuracy: 0.7005\n"
          ]
        }
      ],
      "source": [
        "history = googlenet.fit(flowers_train, epochs=10, validation_data=flowers_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib072JC1R_S6"
      },
      "source": [
        "##**ResidualNet - ResNet-34**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-4TYpvJSU4y"
      },
      "source": [
        "### Residual Block of ResNet-34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMuD5kWRNcB2"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, filter, stride=1, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.filter = filter\n",
        "        self.stride = stride\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            keras.layers.Conv2D(filters=filter,\n",
        "                                kernel_size=3,\n",
        "                                strides=stride,\n",
        "                                padding=\"same\",\n",
        "                                use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            keras.layers.Conv2D(filters=filter,\n",
        "                                kernel_size=3,\n",
        "                                strides=1,\n",
        "                                padding=\"same\",\n",
        "                                use_bias=False),\n",
        "            keras.layers.BatchNormalization()\n",
        "        ]\n",
        "        self.shortcut_layers = []\n",
        "        if stride > 1:\n",
        "            self.shortcut_layers = [\n",
        "                keras.layers.Conv2D(filters=filter,\n",
        "                                    kernel_size=1,\n",
        "                                    strides=stride,\n",
        "                                    padding=\"same\",\n",
        "                                    use_bias=False),\n",
        "                keras.layers.BatchNormalization()\n",
        "            ]\n",
        "\n",
        "    def call(self, X):\n",
        "        Z_main = X\n",
        "        for layer in self.main_layers:\n",
        "          Z_main = layer(Z_main)\n",
        "        Z_shortcut = X\n",
        "        for layer in self.shortcut_layers:\n",
        "          Z_shortcut = layer(Z_shortcut)\n",
        "        return self.activation(Z_main + Z_shortcut)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"filter\": self.filter,\n",
        "                \"stride\": self.stride,\n",
        "                \"activation\": keras.activations.serialize(self.activation)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S36Lkaz_Q6cq"
      },
      "source": [
        "### ResNet-34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRPbqkcdR0y0"
      },
      "outputs": [],
      "source": [
        "class ResNet34(keras.Model):\n",
        "    def __init__(self, output_dim=10, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.main_layers = [\n",
        "            keras.layers.Conv2D(filters=64,\n",
        "                                kernel_size=7,\n",
        "                                strides=2,\n",
        "                                padding=\"same\",\n",
        "                                use_bias=False),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Activation(\"relu\"),\n",
        "\n",
        "            keras.layers.MaxPool2D(pool_size=3,\n",
        "                                   strides=2,\n",
        "                                   padding=\"same\")\n",
        "        ]\n",
        "        prev_filter = 64\n",
        "        for res_layer_filter in [64]*3 + [128]*4 + [256]*6 + [512]*3:\n",
        "            stride = 1 if res_layer_filter == prev_filter else 2\n",
        "            self.main_layers += [ResidualBlock(res_layer_filter, stride)]\n",
        "            prev_filter = res_layer_filter\n",
        "        self.main_layers += [\n",
        "                keras.layers.GlobalAvgPool2D(),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(10, activation=\"softmax\")\n",
        "            ]\n",
        "\n",
        "    def call(self, X):\n",
        "        Z = X\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        return Z\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config,\n",
        "                \"output_dim\": self.output_dim}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cVD1i_sU5j0"
      },
      "outputs": [],
      "source": [
        "resnet = ResNet34(output_dim=num_classes)\n",
        "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.05, momentum=0.9, nesterov=True, decay=0.01)\n",
        "resnet.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
        "               metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "1lQ6mk-oVBoO",
        "outputId": "ee5e67eb-8fa9-4460-fef1-3e0ebdc81a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "86/86 [==============================] - 1992s 23s/step - loss: 1.6438 - accuracy: 0.4262 - val_loss: 187.4589 - val_accuracy: 0.1833\n",
            "Epoch 2/17\n",
            "37/86 [===========>..................] - ETA: 16:58 - loss: 1.2151 - accuracy: 0.5279"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7dd363ce9b44>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflowers_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflowers_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1263\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = resnet.fit(flowers_train, epochs=17, validation_data=flowers_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI5BKqXIOd0X"
      },
      "source": [
        "## Xception\n",
        "![picture](https://drive.google.com/uc?export=view&id=1_7QpRPmVSdmNe5JBkbcq0lDFsPTP0al9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHTPuagPOka4"
      },
      "source": [
        "## SENet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SE Block"
      ],
      "metadata": {
        "id": "PNnWNSBIMbXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(keras.layers.Layer):\n"
      ],
      "metadata": {
        "id": "R8GgumdzM17z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert SE Block into convolutional units (Residual, Inception, Xception, ...)"
      ],
      "metadata": {
        "id": "eT_KvLLcMdzp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUUXDSkOOwxM"
      },
      "source": [
        "## FCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDEQSRRQl1im"
      },
      "source": [
        "## **Transfer Learning by using pre-trained Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCnyHnrCmGY4"
      },
      "source": [
        "In this section, we will use pre-trained Xception model to classify _tf_flowers_ dataset. We make use of pre-trained low layers of Xception. First, we must import the dataset by using TensorFLow Datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C_03bZxSpEU",
        "outputId": "d1a0618c-c9d2-4a8e-9156-5119fd3ec1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "                                                  include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUagtHl9S5RI"
      },
      "outputs": [],
      "source": [
        "avg = keras.layers.GlobalAvgPool2D()(base_model.output)\n",
        "output = keras.layers.Dense(num_classes, activation=\"softmax\")(avg)\n",
        "model = keras.Model(inputs=[base_model.input], outputs=[output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-lzgfd0TuTP"
      },
      "source": [
        "We should freeze the shallow layers of pre-trained model while training new model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjjbiKPyTtqG"
      },
      "outputs": [],
      "source": [
        "for pre_trained_layers in base_model.layers:\n",
        "    pre_trained_layers.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KfVemHMUYmn",
        "outputId": "1df5ecc8-477b-4c55-d17f-9fb52c869fd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.legacy.SGD(lr=0.2, momentum=0.9, nesterov=True, decay=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWv2q_raVFiD",
        "outputId": "a284c3c9-f856-42dc-c9da-f27f227c1b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "86/86 [==============================] - 34s 243ms/step - loss: 1.5902 - accuracy: 0.7980 - val_loss: 1.1824 - val_accuracy: 0.8439\n",
            "Epoch 2/5\n",
            "86/86 [==============================] - 18s 212ms/step - loss: 0.4063 - accuracy: 0.9179 - val_loss: 0.7446 - val_accuracy: 0.8639\n",
            "Epoch 3/5\n",
            "86/86 [==============================] - 19s 216ms/step - loss: 0.1727 - accuracy: 0.9531 - val_loss: 0.6856 - val_accuracy: 0.8675\n",
            "Epoch 4/5\n",
            "86/86 [==============================] - 19s 218ms/step - loss: 0.1063 - accuracy: 0.9658 - val_loss: 0.6715 - val_accuracy: 0.8693\n",
            "Epoch 5/5\n",
            "86/86 [==============================] - 19s 216ms/step - loss: 0.0715 - accuracy: 0.9789 - val_loss: 0.6497 - val_accuracy: 0.8693\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(flowers_train, epochs=5, validation_data=flowers_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0yJM_DSVkaG"
      },
      "outputs": [],
      "source": [
        "for pre_trained_layers in base_model.layers:\n",
        "    pre_trained_layers.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJfCxnriVptP",
        "outputId": "5f2a849f-35df-40d3-9f3f-04725d758583"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.legacy.SGD(lr=0.2, momentum=0.9, nesterov=True, decay=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1adzWKZVsjF",
        "outputId": "e4629a15-7dc9-49f7-b6bf-9fa727ba35eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "86/86 [==============================] - 64s 632ms/step - loss: 1.3757 - accuracy: 0.4055 - val_loss: 19.7443 - val_accuracy: 0.1996\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 49s 566ms/step - loss: 1.0925 - accuracy: 0.5523 - val_loss: 4.1676 - val_accuracy: 0.4156\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 53s 620ms/step - loss: 0.8380 - accuracy: 0.6675 - val_loss: 4.2877 - val_accuracy: 0.4247\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 49s 567ms/step - loss: 0.6228 - accuracy: 0.7758 - val_loss: 0.7717 - val_accuracy: 0.7350\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - 54s 623ms/step - loss: 0.4908 - accuracy: 0.8249 - val_loss: 0.9275 - val_accuracy: 0.7350\n",
            "Epoch 6/20\n",
            "86/86 [==============================] - 51s 588ms/step - loss: 0.3679 - accuracy: 0.8750 - val_loss: 0.5659 - val_accuracy: 0.8185\n",
            "Epoch 7/20\n",
            "86/86 [==============================] - 49s 575ms/step - loss: 0.2696 - accuracy: 0.9081 - val_loss: 0.8135 - val_accuracy: 0.7786\n",
            "Epoch 8/20\n",
            "86/86 [==============================] - 51s 596ms/step - loss: 0.2634 - accuracy: 0.9052 - val_loss: 0.6420 - val_accuracy: 0.8113\n",
            "Epoch 9/20\n",
            "86/86 [==============================] - 52s 604ms/step - loss: 0.1719 - accuracy: 0.9408 - val_loss: 0.7207 - val_accuracy: 0.7931\n",
            "Epoch 10/20\n",
            "86/86 [==============================] - 51s 596ms/step - loss: 0.1697 - accuracy: 0.9477 - val_loss: 1.2183 - val_accuracy: 0.7241\n",
            "Epoch 11/20\n",
            "86/86 [==============================] - 53s 619ms/step - loss: 0.1419 - accuracy: 0.9546 - val_loss: 0.7259 - val_accuracy: 0.7858\n",
            "Epoch 12/20\n",
            "86/86 [==============================] - 53s 620ms/step - loss: 0.0946 - accuracy: 0.9698 - val_loss: 0.5254 - val_accuracy: 0.8367\n",
            "Epoch 13/20\n",
            "86/86 [==============================] - 50s 578ms/step - loss: 0.0740 - accuracy: 0.9771 - val_loss: 1.0003 - val_accuracy: 0.7913\n",
            "Epoch 14/20\n",
            "86/86 [==============================] - 50s 585ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.5344 - val_accuracy: 0.8766\n",
            "Epoch 15/20\n",
            "86/86 [==============================] - 54s 624ms/step - loss: 0.0467 - accuracy: 0.9855 - val_loss: 0.5347 - val_accuracy: 0.8784\n",
            "Epoch 16/20\n",
            "86/86 [==============================] - 53s 620ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 0.6077 - val_accuracy: 0.8494\n",
            "Epoch 17/20\n",
            "86/86 [==============================] - 53s 621ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.4826 - val_accuracy: 0.8784\n",
            "Epoch 18/20\n",
            "86/86 [==============================] - 53s 620ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.5658 - val_accuracy: 0.8494\n",
            "Epoch 19/20\n",
            "35/86 [===========>..................] - ETA: 27s - loss: 0.0235 - accuracy: 0.9937"
          ]
        }
      ],
      "source": [
        "history = model.fit(flowers_train, epochs=20, validation_data=flowers_valid)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "-lZxovFDONJw",
        "kRexC_LEKc5u",
        "heBvcdeoiNPY",
        "CkKI7j2hCL2d",
        "6fw0AcFR92Kw",
        "OfoOaBRHBz2O"
      ],
      "provenance": [],
      "mount_file_id": "1-kOGtZBA_AzIdmP4WqZ4qnacSh7fsIMe",
      "authorship_tag": "ABX9TyNDFa8McNmMAwU64Kj1bZxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96ee3dba90d543a69b868e4c31642c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dd0c096ebdb4d94a5776ae4d5a2441d",
              "IPY_MODEL_0c410e2b0ee344cc95770b06a8efc8b2",
              "IPY_MODEL_5aad7bac3b96432493c47381e72af3b2"
            ],
            "layout": "IPY_MODEL_e5ae900f485847a4ae917f5889305b1e"
          }
        },
        "3dd0c096ebdb4d94a5776ae4d5a2441d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305f6a099992467da877923174cee107",
            "placeholder": "​",
            "style": "IPY_MODEL_a1577d1009ff4d82a8a2438df5fcf89e",
            "value": "Dl Completed...: 100%"
          }
        },
        "0c410e2b0ee344cc95770b06a8efc8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a88738561943b9a0150286a6c2a27f",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2676a56848c0409a89127512d68fce8e",
            "value": 5
          }
        },
        "5aad7bac3b96432493c47381e72af3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ecedb6245de4371bb774acb8ae0d939",
            "placeholder": "​",
            "style": "IPY_MODEL_68740fa190bc43e785282c7c9e79c3b6",
            "value": " 5/5 [00:05&lt;00:00,  1.32s/ file]"
          }
        },
        "e5ae900f485847a4ae917f5889305b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305f6a099992467da877923174cee107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1577d1009ff4d82a8a2438df5fcf89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09a88738561943b9a0150286a6c2a27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2676a56848c0409a89127512d68fce8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ecedb6245de4371bb774acb8ae0d939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68740fa190bc43e785282c7c9e79c3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}